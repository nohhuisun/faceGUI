import tkinter as tk
from tkinter import ttk, messagebox
import sys
import os
import subprocess

# Check if running in nhuisun_face_py310 environment
def check_and_rerun_in_correct_env():
    """Check for required modules; if missing, rerun in nhuisun_face_py310."""
    conda_env_name = "nhuisun_face_py310"
    current_env = os.environ.get("CONDA_DEFAULT_ENV", "")
    
    # If already in the correct env, return early
    if current_env == conda_env_name:
        return
    
    # Try importing required modules
    required_modules = [("cv2", "opencv-python"), ("mediapipe", "mediapipe"), ("PIL", "Pillow")]
    missing = []
    for mod_name, pkg_name in required_modules:
        try:
            __import__(mod_name)
        except ModuleNotFoundError:
            missing.append(pkg_name)
    
    # If any module is missing, rerun in the correct environment
    if missing:
        script_path = os.path.abspath(__file__)
        conda_exe = r"C:\Users\504\miniconda3\Scripts\conda.exe"
        
        # Try to rerun
        try:
            cmd = [conda_exe, "run", "-n", conda_env_name, "--no-capture-output", "python", script_path]
            print(f"Switching to {conda_env_name} environment...", file=sys.stderr)
            result = subprocess.run(cmd, check=False)
            sys.exit(result.returncode)
        except Exception as e:
            err_msg = (
                f"Missing modules: {', '.join(missing)}\n\n"
                f"Please run this script using the Conda env '{conda_env_name}':\n\n"
                f"{conda_exe} run -n {conda_env_name} --no-capture-output python \"{script_path}\""
            )
            print(err_msg, file=sys.stderr)
            try:
                messagebox.showerror("Missing dependencies", err_msg)
            except Exception:
                pass
            sys.exit(1)

# Check environment at startup
check_and_rerun_in_correct_env()

try:
    import cv2
except ModuleNotFoundError as e:
    print(f"Failed to import cv2: {e}", file=sys.stderr)
    sys.exit(1)

import mediapipe as mp # Dlib ëŒ€ì‹  MediaPipe ì‚¬ìš©
from PIL import Image, ImageTk
import numpy as np
import math
import logging
import os
from tkinter import filedialog
from typing import Optional, Tuple

# --- 1. MediaPipe ì´ˆê¸°í™” ---
# MediaPipe Face Mesh ì†”ë£¨ì…˜ ì´ˆê¸°í™”
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    max_num_faces=1,             # í•œ ë²ˆì— ê°ì§€í•  ìµœëŒ€ ì–¼êµ´ ìˆ˜
    refine_landmarks=True,       # ëœë“œë§ˆí¬ ì •ë°€ë„ ê°œì„ 
    min_detection_confidence=0.5,# ìµœì†Œ ê°ì§€ ì‹ ë¢°ë„
    min_tracking_confidence=0.5  # ìµœì†Œ ì¶”ì  ì‹ ë¢°ë„
)

# --- ë¡œê±° ì„¤ì • (íŒŒì¼ì— ë””ë²„ê·¸ ë¡œê·¸ ê¸°ë¡) ---
LOG_PATH = os.path.join(os.path.dirname(__file__), "face01_debug.log")
logger = logging.getLogger("face01")
logger.setLevel(logging.DEBUG)
if not logger.handlers:
    fh = logging.FileHandler(LOG_PATH, encoding="utf-8")
    fh.setLevel(logging.DEBUG)
    fmt = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
    fh.setFormatter(fmt)
    logger.addHandler(fh)

logger.debug("Initialized MediaPipe FaceMesh with refine_landmarks=%s, max_num_faces=%s, min_detection_confidence=%s, min_tracking_confidence=%s",
             True, 1, 0.5, 0.5)


def try_open_camera(index: int = 0) -> Tuple[Optional[cv2.VideoCapture], str]:
    """Try opening camera using several backends. Returns (cap, description).
    If none succeed, returns (None, last_description).
    """
    backends = [None]
    # Try common Windows backends if available
    try:
        backends.append(cv2.CAP_DSHOW)
    except Exception:
        pass
    try:
        backends.append(cv2.CAP_MSMF)
    except Exception:
        pass
    last_desc = "none"
    for b in backends:
        try:
            if b is None:
                cap = cv2.VideoCapture(index)
                desc = f"index={index} (default)"
            else:
                cap = cv2.VideoCapture(index, b)
                desc = f"index={index} backend={b}"
            ok = cap.isOpened()
            logger.debug("try_open_camera: tried %s -> isOpened=%s", desc, ok)
            if ok:
                return cap, desc
            else:
                try:
                    cap.release()
                except Exception:
                    pass
            last_desc = desc
        except Exception as e:
            logger.exception("try_open_camera exception for backend %s: %s", b, e)
    return None, last_desc


def list_available_cameras(max_index: int = 5):
    """Return a list of camera indices that can be opened."""
    available = []
    for i in range(0, max_index + 1):
        try:
            cap = None
            if hasattr(cv2, 'CAP_DSHOW'):
                cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
            else:
                cap = cv2.VideoCapture(i)
            ok = cap.isOpened()
            if ok:
                available.append(i)
            try:
                cap.release()
            except Exception:
                pass
        except Exception:
            pass
    logger.debug("list_available_cameras -> %s", available)
    return available

# --- 2. ê´€ìƒ ë¶„ì„ í•¨ìˆ˜ ---
# MediaPipe Face MeshëŠ” ê¸°ë³¸ 468ê°œ(0-467) ëœë“œë§ˆí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
# `refine_landmarks=True` ì„¤ì • ì‹œ ëˆˆ ê´€ë ¨ ì¶”ê°€ ëœë“œë§ˆí¬(í™ì±„ ë“±)ë¡œ ì´ 478ê°œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ì£¼ìš” íŠ¹ì§•ì  ì¸ë±ìŠ¤ (MediaPipe Face Mesh ê¸°ì¤€, ëŒ€ëµì ì¸ ìœ„ì¹˜)
LEFT_EYE_INNER = 33
LEFT_EYE_OUTER = 133
NOSE_TIP = 1
MOUTH_UPPER = 13
MOUTH_LOWER = 14
CHIN_CENTER = 199

def get_landmark_coords(landmarks, index, width, height):
    """MediaPipe ëœë“œë§ˆí¬ ê°ì²´ì—ì„œ í”½ì…€ ì¢Œí‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    # ëœë“œë§ˆí¬ ì¢Œí‘œëŠ” 0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì •ê·œí™”ëœ ê°’ì…ë‹ˆë‹¤.
    try:
        if not landmarks:
            return None
        lm_list = landmarks.landmark
        if index < 0 or index >= len(lm_list):
            logger.debug("get_landmark_coords: index %s out of range (len=%s)", index, len(lm_list))
            return None
        lm = lm_list[index]
        x = int(lm.x * width)
        y = int(lm.y * height)
        return x, y
    except Exception as e:
        logger.exception("get_landmark_coords error: %s", e)
        return None

def calculate_distance(p1_x, p1_y, p2_x, p2_y):
    """ë‘ ì  ì‚¬ì´ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    return math.sqrt((p1_x - p2_x)**2 + (p1_y - p2_y)**2)

def analyze_physiognomy_mp(landmarks, frame_width, frame_height):
    """
    MediaPipe Face Mesh ëœë“œë§ˆí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ìƒ ì •ë³´ë¥¼ ë¶„ì„í•˜ê³  ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ê¸°ë³¸ 468ê°œ ì´ìƒì˜ ëœë“œë§ˆí¬ê°€ ìˆì–´ì•¼ ì •ìƒ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    # (refine_landmarks=Trueì¼ ë•ŒëŠ” 478ê°œê°€ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—„ê²©í•œ ë“±í˜¸ ê²€ì‚¬ëŠ” ì œê±°)
    if not landmarks or len(landmarks.landmark) < 468:
        logger.debug("analyze_physiognomy_mp: insufficient landmarks (%s)",
                     0 if not landmarks else len(landmarks.landmark))
        return "ì–¼êµ´ ëœë“œë§ˆí¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    analysis_results = []
    
    # í”½ì…€ ì¢Œí‘œ ì–»ê¸° (ì•ˆì „í•˜ê²Œ None ì²´í¬)
    coords = {}
    for name, idx in (('nose_tip', NOSE_TIP), ('mouth_upper', MOUTH_UPPER), ('mouth_lower', MOUTH_LOWER),
                      ('left_eye_inner', LEFT_EYE_INNER), ('left_eye_outer', LEFT_EYE_OUTER)):
        val = get_landmark_coords(landmarks, idx, frame_width, frame_height)
        if val is None:
            logger.debug("analyze_physiognomy_mp: missing landmark %s (index %s)", name, idx)
            return "í•„ìš”í•œ ì–¼êµ´ ëœë“œë§ˆí¬ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        coords[name] = val

    nose_tip_x, nose_tip_y = coords['nose_tip']
    mouth_upper_x, mouth_upper_y = coords['mouth_upper']
    mouth_lower_x, mouth_lower_y = coords['mouth_lower']
    left_eye_inner_x, left_eye_inner_y = coords['left_eye_inner']
    left_eye_outer_x, left_eye_outer_y = coords['left_eye_outer']
    
    # 1. ì¸ì¤‘ ê¸¸ì´ (ì½” ë ~ ìœ—ì…ìˆ )
    philtrum_length = calculate_distance(nose_tip_x, nose_tip_y, mouth_upper_x, mouth_upper_y)
    analysis_results.append(f"ğŸ—£ï¸ ì¸ì¤‘ ê¸¸ì´ (ì¶”ì •): {int(philtrum_length)} í”½ì…€")
    if philtrum_length > 30:
        analysis_results.append(" - ì¸ì¤‘ì´ ê¸¸ì–´ ê±´ê°•í•˜ê³  ì•ˆì •ì ì¸ ì‚¶ì„ ì¶”êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        analysis_results.append(" - ì¸ì¤‘ì´ ë³´í†µì´ì–´ì„œ ì†”ì§í•˜ê³  í™œë™ì ì¸ ì„±í–¥ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 2. ì…ìˆ  ë‘ê»˜ (ìœ—ì…ìˆ  ì¤‘ì•™ ~ ì•„ë«ì…ìˆ  ì¤‘ì•™)
    lip_thickness = calculate_distance(mouth_upper_x, mouth_upper_y, mouth_lower_x, mouth_lower_y)
    analysis_results.append(f"ğŸ‘„ ì…ìˆ  ë‘ê»˜ (ì¶”ì •): {int(lip_thickness)} í”½ì…€")
    if lip_thickness > 15:
        analysis_results.append(" - ì…ìˆ ì´ ë„í†°í•˜ì—¬ ì¸ì •ì´ ë§ê³  ì‹ë³µì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        analysis_results.append(" - ì…ìˆ ì´ ì–‡ê±°ë‚˜ ë³´í†µì´ì–´ì„œ ì´ì„±ì ì´ê³  ì„¬ì„¸í•œ ê²½í–¥ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 3. ëˆˆì˜ í­ (ì™¼ìª½ ëˆˆ ì•ˆìª½ ë ~ ë°”ê¹¥ìª½ ë)
    eye_width = calculate_distance(left_eye_inner_x, left_eye_inner_y, left_eye_outer_x, left_eye_outer_y)
    analysis_results.append(f"ğŸ‘ï¸ ëˆˆ í­ (ì¶”ì •): {int(eye_width)} í”½ì…€")
    if eye_width > 60:
        analysis_results.append(" - ëˆˆì´ ì»¤ì„œ ê°ì • í‘œí˜„ì´ í’ë¶€í•˜ê³  í˜¸ê¸°ì‹¬ì´ ë§ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        analysis_results.append(" - ëˆˆì´ ì‘ê±°ë‚˜ ë³´í†µì´ì–´ì„œ ì‹ ì¤‘í•˜ê³  ì§‘ì¤‘ë ¥ì´ ê°•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return "âœ… ê´€ìƒ ë¶„ì„ ê²°ê³¼ (MediaPipe ì˜ˆì‹œ):\n" + "\n".join(analysis_results)

# --- 3. GUI í´ë˜ìŠ¤ ì •ì˜ (Tkinter) ---
class PhysiognomyApp:
    def __init__(self, master):
        self.master = master
        master.title("ì›¹ìº  ê´€ìƒ ë¶„ì„ í”„ë¡œê·¸ë¨ (MediaPipe Ver.)")
        master.protocol("WM_DELETE_WINDOW", self.on_closing)
        # ì°½ì„ ì•ìœ¼ë¡œ ì˜¬ë ¤ ì‚¬ìš©ìê°€ ë¹„ë””ì˜¤ ì˜ì—­ì„ ë°”ë¡œ ë³¼ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
        try:
            master.lift()
            master.attributes('-topmost', True)
            # ì ê¹ ìµœìƒìœ„ë¡œ ë§Œë“  ë’¤ ì›ë˜ëŒ€ë¡œ ëŒë ¤ë†“ê¸°
            master.after(200, lambda: master.attributes('-topmost', False))
        except Exception:
            pass

        # ì¹´ë©”ë¼ ëª©ë¡ í™•ì¸ ë° ì„ íƒ UI
        cameras = list_available_cameras(4)
        self.cap = None
        if cameras:
            # ê¸°ë³¸ìœ¼ë¡œ ì²« ì¹´ë©”ë¼ ì„ íƒí•´ì„œ ì˜¤í”ˆ
            selected_idx = cameras[0]
            self.cap, cap_desc = try_open_camera(selected_idx)
            if self.cap is None or not self.cap.isOpened():
                logger.warning("Could not open default camera %s, cameras list=%s", selected_idx, cameras)
            else:
                logger.info("Camera opened successfully: %s", cap_desc)
        else:
            logger.warning("No available cameras detected: %s", cameras)
        
        self.width = 640
        self.height = 480
        if self.cap is not None:
            try:
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.width)
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.height)
            except Exception:
                pass
        logger.debug("Camera opened: %s", False if self.cap is None else self.cap.isOpened())
        logger.debug("Requested frame size: %sx%s", self.width, self.height)
        logger.debug("Camera opened: %s", self.cap.isOpened())
        logger.debug("Requested frame size: %sx%s", self.width, self.height)

        # GUI ë ˆì´ì•„ì›ƒ ì„¤ì •
        main_frame = ttk.Frame(master, padding="10")
        main_frame.pack(fill="both", expand=True)

        # ë¹„ë””ì˜¤ í”„ë ˆì„ (ì™¼ìª½)
        self.video_label = ttk.Label(main_frame, borderwidth=2, relief="groove")
        self.video_label.pack(side="left", padx=10, pady=10)

        # ë¶„ì„ ê²°ê³¼ í”„ë ˆì„ (ì˜¤ë¥¸ìª½)
        analysis_panel = ttk.Frame(main_frame, padding="10")
        analysis_panel.pack(side="right", fill="y", padx=10, pady=10)

        ttk.Label(analysis_panel, text="ê´€ìƒ ë¶„ì„ ê²°ê³¼", font=("Helvetica", 18, "bold")).pack(pady=10)
        
        self.analysis_text_widget = tk.Text(analysis_panel, wrap="word", width=45, height=25, font=("Helvetica", 12), 
                                            borderwidth=2, relief="solid")
        self.analysis_text_widget.pack(pady=5, padx=5, fill="both", expand=True)
        self.analysis_text_widget.insert(tk.END, "MediaPipeë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ì„ ì¸ì‹í•©ë‹ˆë‹¤.")
        
        self.btn_quit = ttk.Button(analysis_panel, text="í”„ë¡œê·¸ë¨ ì¢…ë£Œ", command=self.on_closing)
        self.btn_quit.pack(pady=20)
        # ì¹´ë©”ë¼ ì„ íƒ ì½¤ë³´ + ì´ë¯¸ì§€ ë¡œë“œ ë²„íŠ¼
        cam_controls = ttk.Frame(analysis_panel)
        cam_controls.pack(pady=5)
        ttk.Label(cam_controls, text="ì¹´ë©”ë¼ ì„ íƒ:").grid(row=0, column=0, sticky="w")
        self.cam_var = tk.StringVar()
        cam_list = [str(c) for c in list_available_cameras(6)]
        self.cam_combo = ttk.Combobox(cam_controls, textvariable=self.cam_var, values=cam_list, width=8)
        if cam_list:
            self.cam_combo.set(cam_list[0])
        self.cam_combo.grid(row=0, column=1, padx=5)
        self.btn_select_cam = ttk.Button(cam_controls, text="ì„ íƒ", command=self.select_camera)
        self.btn_select_cam.grid(row=0, column=2, padx=5)

        self.btn_load_image = ttk.Button(cam_controls, text="ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°", command=self.load_image)
        self.btn_load_image.grid(row=1, column=0, columnspan=3, pady=6)
        # ìƒíƒœ ë ˆì´ë¸”: ì¹´ë©”ë¼ ì—°ê²°/ëœë“œë§ˆí¬ ìˆ˜ë¥¼ í‘œì‹œ
        self.status_var = tk.StringVar(value="ì¹´ë©”ë¼ ìƒíƒœ: í™•ì¸ ì¤‘...")
        self.status_label = ttk.Label(analysis_panel, textvariable=self.status_var, foreground="blue")
        self.status_label.pack(pady=6)
        
        # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë£¨í”„ ì‹œì‘
        self.delay = 15 
        # ë””ë²„ê·¸ í”Œë˜ê·¸: íŒŒì¼ì— ê°ì§€ ìƒíƒœë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
        self.DEBUG = True
        self.update_video()

    def update_video(self):
        """ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ê³ , ì–¼êµ´ì„ ì¸ì‹í•˜ì—¬ íŠ¹ì§•ì ì„ í‘œì‹œí•œ í›„ GUIì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        # ì•ˆì „í•˜ê²Œ ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ ì½ê¸°
        frame = None
        ret = False
        if self.cap is not None and self.cap.isOpened():
            try:
                ret, frame = self.cap.read()
            except Exception:
                ret = False

        current_analysis_text = "ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        if ret and frame is not None:
            # 1. MediaPipe ì²˜ë¦¬
            frame = cv2.flip(frame, 1) # ì¢Œìš° ë°˜ì „ (ê±°ìš¸ ëª¨ë“œ)
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = face_mesh.process(rgb_frame) # MediaPipe ë¶„ì„ ì‹¤í–‰

            if results and results.multi_face_landmarks:
                # ì²« ë²ˆì§¸ ê°ì§€ëœ ì–¼êµ´ë§Œ ì‚¬ìš©
                landmarks = results.multi_face_landmarks[0]
                if self.DEBUG:
                    try:
                        cnt = len(landmarks.landmark)
                        logger.debug("Face landmarks detected: %s", cnt)
                        coords_sample = [(round(lm.x,3), round(lm.y,3)) for lm in landmarks.landmark[:3]]
                        logger.debug("Sample landmarks (normalized): %s", coords_sample)
                    except Exception as e:
                        logger.exception("Error logging landmarks: %s", e)

                # 2. íŠ¹ì§•ì  ê·¸ë¦¬ê¸° (ì‹¤ì œ í”„ë ˆì„ í¬ê¸° ì‚¬ìš©)
                fh, fw = rgb_frame.shape[:2]
                for lm in landmarks.landmark:
                    x = int(lm.x * fw)
                    y = int(lm.y * fh)
                    cv2.circle(rgb_frame, (x, y), 1, (0, 255, 0), -1)

                # 3. ê´€ìƒ ë¶„ì„ ì‹¤í–‰ (í”½ì…€ ê³„ì‚°ì— ì‹¤ì œ í”„ë ˆì„ í¬ê¸°ë¥¼ ì „ë‹¬)
                current_analysis_text = analyze_physiognomy_mp(landmarks, fw, fh)
                # ìƒíƒœ í‘œì‹œ ì—…ë°ì´íŠ¸
                try:
                    self.status_var.set(f"ì¹´ë©”ë¼: ì—°ê²°ë¨  ëœë“œë§ˆí¬: {len(landmarks.landmark)}")
                except Exception:
                    self.status_var.set("ì¹´ë©”ë¼: ì—°ê²°ë¨  ëœë“œë§ˆí¬: ?")

            # ë¶„ì„ ê²°ê³¼ë¥¼ GUI í…ìŠ¤íŠ¸ ìœ„ì ¯ì— ì—…ë°ì´íŠ¸
            self.analysis_text_widget.delete(1.0, tk.END)
            self.analysis_text_widget.insert(tk.END, current_analysis_text)

            # OpenCV í”„ë ˆì„ì„ Tkinterì—ì„œ í‘œì‹œí•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ë¡œ ë³€í™˜
            img = Image.fromarray(rgb_frame)
            imgtk = ImageTk.PhotoImage(image=img)
            self.video_label.imgtk = imgtk
            self.video_label.configure(image=imgtk)
        else:
            # ì¹´ë©”ë¼ í”„ë ˆì„ì´ ì—†ì„ ë•ŒëŠ” ë¹ˆ íšŒìƒ‰ ì´ë¯¸ì§€ë¡œ í‘œì‹œ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
            blank = Image.new('RGB', (self.width, self.height), (120,120,120))
            imgtk = ImageTk.PhotoImage(image=blank)
            self.video_label.imgtk = imgtk
            self.video_label.configure(image=imgtk)
            # ì¹´ë©”ë¼ê°€ ì—´ë ¤ ìˆì§€ ì•Šê±°ë‚˜ í”„ë ˆì„ì„ ëª» ë°›ì•„ì™”ì„ ë•Œ ìƒíƒœ í‘œì‹œ
            try:
                if self.cap is None or not self.cap.isOpened():
                    self.status_var.set("ì¹´ë©”ë¼: ì—°ê²°ë˜ì§€ ì•ŠìŒ")
                else:
                    self.status_var.set("ì¹´ë©”ë¼: ì—°ê²°ë¨(í”„ë ˆì„ ì—†ìŒ)")
            except Exception:
                self.status_var.set("ì¹´ë©”ë¼: ìƒíƒœ ì•Œ ìˆ˜ ì—†ìŒ")

        # ë‹¤ìŒ ì—…ë°ì´íŠ¸ ì˜ˆì•½
        self.master.after(self.delay, self.update_video)

    def select_camera(self):
        """Reopen camera from combobox selection."""
        sel = self.cam_var.get()
        try:
            idx = int(sel)
        except Exception:
            messagebox.showwarning("ì¹´ë©”ë¼ ì„ íƒ", "ìœ íš¨í•œ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            return
        # close previous
        if self.cap is not None:
            try:
                self.cap.release()
            except Exception:
                pass
        self.cap, desc = try_open_camera(idx)
        if self.cap is None or not self.cap.isOpened():
            messagebox.showerror("ì¹´ë©”ë¼ ì˜¤ë¥˜", f"ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {desc}")
            logger.error("select_camera failed: %s", desc)
        else:
            logger.info("select_camera opened: %s", desc)

    def load_image(self):
        """Open an image file and run analysis once (headless path)."""
        path = filedialog.askopenfilename(filetypes=[("Image files","*.jpg *.jpeg *.png *.bmp"), ("All files","*.*")])
        if not path:
            return
        # ì¼ë¶€ Windows/OpenCV ë¹Œë“œì—ì„œëŠ” í•œê¸€(ìœ ë‹ˆì½”ë“œ) ê²½ë¡œì—ì„œ cv2.imreadê°€ ì‹¤íŒ¨í•©ë‹ˆë‹¤.
        # ì•ˆì •ì ìœ¼ë¡œ ì—´ê¸° ìœ„í•´ ë¨¼ì € PILë¡œ ì‹œë„í•˜ê³ , ì‹¤íŒ¨í•˜ë©´ numpy+cv2.imdecodeë¡œ fallback í•©ë‹ˆë‹¤.
        try:
            pil_img = Image.open(path).convert('RGB')
            rgb = np.array(pil_img)
        except Exception as e:
            logger.exception("load_image: PIL failed to open image: %s", e)
            try:
                # cv2.imreadê°€ ìœ ë‹ˆì½”ë“œ ê²½ë¡œì—ì„œ ì‹¤íŒ¨í•˜ë©´ fromfile+imdecode ë°©ì‹ ì‚¬ìš©
                data = np.fromfile(path, dtype=np.uint8)
                img_bgr = cv2.imdecode(data, cv2.IMREAD_COLOR)
                if img_bgr is None:
                    raise ValueError('cv2.imdecode returned None')
                rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            except Exception as e2:
                logger.exception("load_image: cv2 fallback also failed: %s", e2)
                messagebox.showerror("ì´ë¯¸ì§€ ì˜¤ë¥˜", f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n{e2}")
                return
        results = face_mesh.process(rgb)
        analysis_text = "ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        if results and results.multi_face_landmarks:
            lm = results.multi_face_landmarks[0]
            # use actual image size
            h, w = rgb.shape[:2]
            analysis_text = analyze_physiognomy_mp(lm, w, h)
            # draw landmarks for display
            for lm_pt in lm.landmark:
                x = int(lm_pt.x * w)
                y = int(lm_pt.y * h)
                cv2.circle(rgb, (x, y), 1, (0,255,0), -1)
        # show in GUI
        img = Image.fromarray(rgb)
        imgtk = ImageTk.PhotoImage(image=img)
        self.video_label.imgtk = imgtk
        self.video_label.configure(image=imgtk)
        self.analysis_text_widget.delete(1.0, tk.END)
        self.analysis_text_widget.insert(tk.END, analysis_text)

    def on_closing(self):
        """GUI ì°½ì´ ë‹«í ë•Œ ì¹´ë©”ë¼ì™€ ì°½ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
        try:
            if self.cap and self.cap.isOpened():
                try:
                    self.cap.release()
                except Exception:
                    pass
        except Exception:
            pass
        # MediaPipe ê°ì²´ í•´ì œ (ì„ íƒ ì‚¬í•­)
        try:
            face_mesh.close()
        except Exception:
            pass
        self.master.destroy()

# --- 4. ë©”ì¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    root = tk.Tk()
    app = PhysiognomyApp(root)
    root.mainloop()